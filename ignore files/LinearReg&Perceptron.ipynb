{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47a2e047",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def read_data(file_path):\n",
    "#     with open(file_path, 'r') as file:\n",
    "#         data = [row.split('\\t') for row in file.read().split('\\n')]\n",
    "#         header = data[0]\n",
    "#         data = [[float(val) if i > 0 else val for i, val in enumerate(row)] for row in data[1:-1]]\n",
    "#     return header, data\n",
    "\n",
    "# def extract_features_target(data):\n",
    "#     features = [row[1:-1] for row in data]  # Exclude the ID column and the last column (target)\n",
    "#     target = [row[-1] for row in data]  # Extract the last column (target)\n",
    "#     return features, target\n",
    "\n",
    "# def split_data(features, target, test_size=0.2, random_state=None):\n",
    "#     num_samples = len(features)\n",
    "#     num_test_samples = int(test_size * num_samples)  # Fix: Change 'test_ratio' to 'test_size'\n",
    "    \n",
    "#     if random_state is not None:\n",
    "#         random.seed(random_state)\n",
    "#         indices = random.sample(range(num_samples), num_test_samples)\n",
    "#     else:\n",
    "#         indices = range(num_test_samples)\n",
    "    \n",
    "#     test_features = [features[i] for i in indices]\n",
    "#     test_target = [target[i] for i in indices]\n",
    "    \n",
    "#     train_features = [features[i] for i in range(num_samples) if i not in indices]\n",
    "#     train_target = [target[i] for i in range(num_samples) if i not in indices]\n",
    "    \n",
    "#     return train_features, train_target, test_features, test_target\n",
    "\n",
    "\n",
    "# #  Training the Model\n",
    "# def train_linear_regression(features, target):\n",
    "#     num_samples = len(features)\n",
    "    \n",
    "#     if num_samples == 0:\n",
    "#         raise ValueError(\"No samples found. Please check your data.\")\n",
    "    \n",
    "#     num_features = len(features[0])\n",
    "    \n",
    "#     if num_features == 0:\n",
    "#         raise ValueError(\"No features found. Please check your data.\")\n",
    "    \n",
    "#     # Initialize weights and bias\n",
    "#     weights = [0.0] * num_features\n",
    "#     bias = 0.0\n",
    "    \n",
    "#     # Learning rate\n",
    "#     learning_rate = 0.0001\n",
    "    \n",
    "#     # Number of iterations (epochs)\n",
    "#     num_epochs = 1000\n",
    "    \n",
    "#     for epoch in range(num_epochs):\n",
    "#         error_sum = 0.0\n",
    "#         for i in range(num_samples):\n",
    "#             prediction = sum(weights[j] * features[i][j] for j in range(num_features)) + bias\n",
    "#             error = target[i] - prediction\n",
    "            \n",
    "#             for j in range(num_features):\n",
    "#                 weights[j] += learning_rate * error * features[i][j]\n",
    "#             bias += learning_rate * error\n",
    "            \n",
    "#             error_sum += error ** 2\n",
    "        \n",
    "#         # Print mean squared error for this epoch\n",
    "#         print(f'Epoch {epoch + 1}: Mean Squared Error = {error_sum / num_samples}')\n",
    "    \n",
    "#     return weights, bias\n",
    "\n",
    "\n",
    "\n",
    "# # Making Predictions\n",
    "# def predict(features, weights, bias):\n",
    "#     predictions = []\n",
    "#     for feature in features:\n",
    "#         prediction = sum(weights[j] * feature[j] for j in range(len(feature))) + bias\n",
    "#         predictions.append(prediction)\n",
    "#     return predictions\n",
    "\n",
    "# #  Evaluating the Model\n",
    "# def mean_squared_error(predictions, actual):\n",
    "#     return sum((p - a) ** 2 for p, a in zip(predictions, actual)) / len(predictions)\n",
    "\n",
    "# # Usage Example\n",
    "# data = read_data(\"handwriting_alzheimers.csv\")\n",
    "# features, target = extract_features_target(data)\n",
    "# train_features, train_target, test_features, test_target = split_data(features, target)\n",
    "\n",
    "# weights, bias = train_linear_regression(train_features, train_target)\n",
    "# predictions = predict(test_features, weights, bias)\n",
    "# mse = mean_squared_error(predictions, test_target)\n",
    "# print(f'Mean Squared Error on Test Data: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f62df3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [[-27365960673877.094]\n",
      " [1418404649242942.5]\n",
      " [106.7034912109375]\n",
      " [521383364810.3556]\n",
      " [382152255900.05054]\n",
      " [586.5325393676758]\n",
      " [204.91064453125]\n",
      " [-591.3680419921875]\n",
      " [1302.5440979003906]\n",
      " [-727987345276.7151]\n",
      " [541.513916015625]\n",
      " [-673.107421875]\n",
      " [511.49871826171875]\n",
      " [-946.162109375]\n",
      " [-159.68756103515625]\n",
      " [584849924299646.0]\n",
      " [293.29076766967773]\n",
      " [323.066650390625]\n",
      " [-1982346333944888.5]\n",
      " [3444927337211463.5]\n",
      " [-235.16717529296875]\n",
      " [61820071287.49432]\n",
      " [33766362503.08664]\n",
      " [-10.179519653320312]\n",
      " [-30.934066772460938]\n",
      " [-3634.32568359375]\n",
      " [-131.22079467773438]\n",
      " [-71459755381.29523]\n",
      " [3650.99658203125]\n",
      " [728.0029907226562]\n",
      " [14.2904052734375]\n",
      " [330.81866455078125]\n",
      " [1168.3699035644531]\n",
      " [1606390825715484.2]\n",
      " [-312.5876178741455]\n",
      " [-336.8681640625]\n",
      " [-4929334203036855.0]\n",
      " [-743307995427564.2]\n",
      " [158.05322265625]\n",
      " [200024173419.72906]\n",
      " [91740568832.09949]\n",
      " [-226.99755859375]\n",
      " [-285.307373046875]\n",
      " [1148.7689819335938]\n",
      " [-581.6065673828125]\n",
      " [-247313630908.21765]\n",
      " [-454.9072265625]\n",
      " [225.67601776123047]\n",
      " [34.39110565185547]\n",
      " [512.0580444335938]\n",
      " [584.6312561035156]\n",
      " [-688536631160521.5]\n",
      " [-258.54893493652344]\n",
      " [20.05950927734375]\n",
      " [966473486403414.8]\n",
      " [-874267162223808.2]\n",
      " [172.7294921875]\n",
      " [-124267229717.27734]\n",
      " [-67355741532.18555]\n",
      " [-296.33636474609375]\n",
      " [249.9906005859375]\n",
      " [-123.16064453125]\n",
      " [390.306884765625]\n",
      " [130331436742.09229]\n",
      " [-104.7911376953125]\n",
      " [-494.0866394042969]\n",
      " [1306.7487182617188]\n",
      " [2348.468017578125]\n",
      " [-623.3843994140625]\n",
      " [-175843353635217.0]\n",
      " [-238.2288055419922]\n",
      " [334.80824279785156]\n",
      " [1035870473072493.6]\n",
      " [686266995980134.4]\n",
      " [916.469841003418]\n",
      " [-72354627071.79321]\n",
      " [-62900704700.395996]\n",
      " [59.14453125]\n",
      " [-1269.8858947753906]\n",
      " [-1505.6082153320312]\n",
      " [-203.5908203125]\n",
      " [84784659268.75732]\n",
      " [1130.8359375]\n",
      " [334.63722229003906]\n",
      " [280.39697265625]\n",
      " [1218.982666015625]\n",
      " [-75.3143310546875]\n",
      " [674683465421316.9]\n",
      " [-682.1961288452148]\n",
      " [431.5103511810303]\n",
      " [-1359078795781715.5]\n",
      " [-650731444692607.1]\n",
      " [238.2362060546875]\n",
      " [221189028209.53613]\n",
      " [145892210210.12988]\n",
      " [716.8315582275391]\n",
      " [-456.90277099609375]\n",
      " [-13603.263305664062]\n",
      " [-171.62784099578857]\n",
      " [-274688172283.53223]\n",
      " [13472.681396484375]\n",
      " [329.3200378417969]\n",
      " [702.775390625]\n",
      " [-952.6129150390625]\n",
      " [427.975830078125]\n",
      " [-164642895644954.06]\n",
      " [-30.994598388671875]\n",
      " [-132.0947265625]\n",
      " [808713692220306.5]\n",
      " [-320259486969767.0]\n",
      " [-550.6454467773438]\n",
      " [-309630841921.0659]\n",
      " [-397749984549.44]\n",
      " [-575.6303787231445]\n",
      " [-392.96266174316406]\n",
      " [7955.520782470703]\n",
      " [1002.962890625]\n",
      " [511325866361.7528]\n",
      " [-7822.1650390625]\n",
      " [-397.336669921875]\n",
      " [-4499.484191894531]\n",
      " [706.2799072265625]\n",
      " [2508.630615234375]\n",
      " [-24364074184032.547]\n",
      " [85.08642578125]\n",
      " [-2.5731201171875]\n",
      " [322592333446642.5]\n",
      " [11995879073738.578]\n",
      " [-338.34645080566406]\n",
      " [-197039955890.8933]\n",
      " [-33043338546.81079]\n",
      " [-91.125244140625]\n",
      " [-7.08056640625]\n",
      " [-6641.43310546875]\n",
      " [-298.68310546875]\n",
      " [217777964687.14746]\n",
      " [6832.97705078125]\n",
      " [230.64990234375]\n",
      " [-474.68701171875]\n",
      " [-127.92953491210938]\n",
      " [-290.798828125]\n",
      " [6657679922080.75]\n",
      " [480.47200775146484]\n",
      " [193.81494140625]\n",
      " [-16400741003841.11]\n",
      " [237782874368974.97]\n",
      " [-670.8225936889648]\n",
      " [324875258613.2063]\n",
      " [92828275188.91821]\n",
      " [-250.1259765625]\n",
      " [917.1038665771484]\n",
      " [-2794.24609375]\n",
      " [-36.86083984375]\n",
      " [-358535457686.55054]\n",
      " [2974.297119140625]\n",
      " [116.16001510620117]\n",
      " [77.30303955078125]\n",
      " [-674.0556640625]\n",
      " [-435.96484375]\n",
      " [122081432609215.81]\n",
      " [-434.8749084472656]\n",
      " [-228.08065605163574]\n",
      " [-310793766429763.7]\n",
      " [-121275468282648.5]\n",
      " [-100.405029296875]\n",
      " [-123490466072.43158]\n",
      " [-97450257828.63696]\n",
      " [-741.731201171875]\n",
      " [-14.45318603515625]\n",
      " [-2607.732666015625]\n",
      " [630.025634765625]\n",
      " [160644860443.0725]\n",
      " [2548.89892578125]\n",
      " [-687.172607421875]\n",
      " [493.319091796875]\n",
      " [597.462890625]\n",
      " [-813.2652946710587]\n",
      " [-59047260449481.984]\n",
      " [767.3978271484375]\n",
      " [120.17645263671875]\n",
      " [164965410680321.94]\n",
      " [-6801.41748046875]\n",
      " [-325.33135986328125]\n",
      " [28994741573.761597]\n",
      " [23052329776.68051]\n",
      " [183.99215698242188]\n",
      " [457.21270751953125]\n",
      " [-1443.31640625]\n",
      " [-1581.4797668457031]\n",
      " [-41292642673.56372]\n",
      " [2525.11328125]\n",
      " [1000.2429809570312]\n",
      " [-244.438720703125]\n",
      " [2303.202392578125]\n",
      " [542.4324035644531]\n",
      " [333.2847900390625]\n",
      " [-362.920166015625]\n",
      " [-644.1259765625]\n",
      " [7079.146957397461]\n",
      " [3685.31640625]\n",
      " [92.573486328125]\n",
      " [1017.035270690918]\n",
      " [435.6864013671875]\n",
      " [448.004638671875]\n",
      " [-133.38970947265625]\n",
      " [157.6121826171875]\n",
      " [165.59925079345703]\n",
      " [-1390.7255859375]\n",
      " [-182.76608848571777]\n",
      " [-129.87328338623047]\n",
      " [-63.85285949707031]\n",
      " [-553.6122131347656]\n",
      " [-208.4150390625]\n",
      " [-10.1495361328125]\n",
      " [23.285125732421875]\n",
      " [-15.84661865234375]\n",
      " [-3788.9453125]\n",
      " [159.61397743225098]\n",
      " [226.3193359375]\n",
      " [-73.25732421875]\n",
      " [-124.27001953125]\n",
      " [-272.5223388671875]\n",
      " [-27.73040771484375]\n",
      " [-1341.0810546875]\n",
      " [-148.205078125]\n",
      " [86.91632080078125]\n",
      " [1237.324951171875]\n",
      " [114.65087890625]\n",
      " [162.9140625]\n",
      " [60.59600830078125]\n",
      " [80.70806884765625]\n",
      " [-391.060546875]\n",
      " [-90.12181663513184]\n",
      " [217.991455078125]\n",
      " [-315.498046875]\n",
      " [-1885.60986328125]\n",
      " [-58.67529296875]\n",
      " [-65.061279296875]\n",
      " [56.9437255859375]\n",
      " [-166.8639793395996]\n",
      " [-37.31550216674805]\n",
      " [-86.0860595703125]\n",
      " [1.728271484375]\n",
      " [184.02818489074707]\n",
      " [84.209716796875]\n",
      " [-66.3738021850586]\n",
      " [-68.47784423828125]\n",
      " [-141.61851501464844]\n",
      " [84.1412353515625]\n",
      " [-49.225341796875]\n",
      " [104.693359375]\n",
      " [-23.550445556640625]\n",
      " [1819.3800659179688]\n",
      " [707.9228515625]\n",
      " [84.34587860107422]\n",
      " [-98.5084228515625]\n",
      " [-95.1622314453125]\n",
      " [-184.019775390625]\n",
      " [112.29473876953125]\n",
      " [-26.025726318359375]\n",
      " [-132.2001953125]\n",
      " [147.0769805908203]\n",
      " [47.910003662109375]\n",
      " [68.17822265625]\n",
      " [-0.2807445526123047]\n",
      " [-140.6507568359375]\n",
      " [35.826171875]\n",
      " [-112.63301086425781]\n",
      " [0.8921451568603516]\n",
      " [98.97998046875]\n",
      " [-626.1123046875]\n",
      " [-230.20389556884766]\n",
      " [70.31026458740234]\n",
      " [212.4407958984375]\n",
      " [178.1489028930664]\n",
      " [-91.6156005859375]\n",
      " [3.2940597534179688]\n",
      " [-194.7247314453125]\n",
      " [-68.63665771484375]\n",
      " [-48.6378173828125]\n",
      " [-91.330078125]\n",
      " [-77.55459308624268]\n",
      " [96.642333984375]\n",
      " [-70.8411865234375]\n",
      " [115.3990478515625]\n",
      " [-129.1705322265625]\n",
      " [-57.288002014160156]\n",
      " [-45.67877197265625]\n",
      " [290.5068359375]\n",
      " [-17.710403442382812]\n",
      " [12.54815673828125]\n",
      " [-80.0430908203125]\n",
      " [-33.482177734375]\n",
      " [-53.56964111328125]\n",
      " [4.3775177001953125]\n",
      " [-14.90423583984375]\n",
      " [14.138198852539062]\n",
      " [10.682861328125]\n",
      " [109.26263427734375]\n",
      " [45.81510925292969]\n",
      " [64.86968994140625]\n",
      " [-77.87112426757812]\n",
      " [45.00179672241211]\n",
      " [154.18618774414062]\n",
      " [42.262939453125]\n",
      " [-70.114990234375]\n",
      " [101.37356567382812]\n",
      " [175.45101928710938]\n",
      " [475.285888671875]\n",
      " [88.7128677368164]\n",
      " [-116.076904296875]\n",
      " [-229.531494140625]\n",
      " [124.93594360351562]\n",
      " [371.81396484375]\n",
      " [-61.20703125]\n",
      " [82.0224609375]\n",
      " [-486.51025390625]\n",
      " [-14.526153564453125]\n",
      " [-77.98724365234375]\n",
      " [-9.133872985839844]\n",
      " [-200.21044921875]\n",
      " [179.06494140625]\n",
      " [28.90875244140625]\n",
      " [46.6978759765625]\n",
      " [-563.6911010742188]\n",
      " [672.417236328125]\n",
      " [-48.384521484375]\n",
      " [49.07099914550781]\n",
      " [8.723190307617188]\n",
      " [-56.4921875]\n",
      " [67.43222045898438]\n",
      " [-67.20196533203125]\n",
      " [-12.563980102539062]\n",
      " [-34.64827632904053]\n",
      " [97.1123046875]\n",
      " [1.8115463256835938]\n",
      " [67.2210693359375]\n",
      " [10.500101089477539]\n",
      " [141.40234375]\n",
      " [-3.84136962890625]\n",
      " [-13.267822265625]\n",
      " [-28.555811882019043]\n",
      " [-732.6927490234375]\n",
      " [211.89572143554688]\n",
      " [-18.2288818359375]\n",
      " [17.126094818115234]\n",
      " [68.13618850708008]\n",
      " [-41.890350341796875]\n",
      " [-5.382072448730469]\n",
      " [-460.828125]\n",
      " [27.268829345703125]\n",
      " [72.039306640625]\n",
      " [420.8574523925781]\n",
      " [-31.714157104492188]\n",
      " [-1.2908935546875]\n",
      " [-23.5738525390625]\n",
      " [1.0919933319091797]\n",
      " [191.05859375]\n",
      " [-8.67938232421875]\n",
      " [-32.073486328125]\n",
      " [52.4521484375]\n",
      " [-100.517333984375]\n",
      " [4.655387878417969]\n",
      " [57.664520263671875]\n",
      " [-116.1412353515625]\n",
      " [2.996795654296875]\n",
      " [50.681640625]\n",
      " [-24.974365234375]\n",
      " [37.29638671875]\n",
      " [-62.052581787109375]\n",
      " [-210.8916015625]\n",
      " [-38.1048583984375]\n",
      " [187.6025390625]\n",
      " [94.99169921875]\n",
      " [316.1728515625]\n",
      " [-162.18115234375]\n",
      " [-21.972442626953125]\n",
      " [-95.2333984375]\n",
      " [37.2034912109375]\n",
      " [691.28173828125]\n",
      " [-33.391448974609375]\n",
      " [-74.068603515625]\n",
      " [-40.5048828125]\n",
      " [173.85546875]\n",
      " [-21.867095947265625]\n",
      " [89.1456298828125]\n",
      " [-39.9217529296875]\n",
      " [-21.010574340820312]\n",
      " [-41.632965087890625]\n",
      " [-22.448654174804688]\n",
      " [-1.5377578735351562]\n",
      " [-4.64794921875]\n",
      " [1.788299560546875]\n",
      " [-160.8621826171875]\n",
      " [-12.1531982421875]\n",
      " [36.553741455078125]\n",
      " [-1000.84130859375]\n",
      " [383.403076171875]\n",
      " [-15.922500610351562]\n",
      " [22.44873046875]\n",
      " [30.176719665527344]\n",
      " [191.8739013671875]\n",
      " [-6.92291259765625]\n",
      " [20.7197265625]\n",
      " [45.12603759765625]\n",
      " [9.038715362548828]\n",
      " [17.775741577148438]\n",
      " [28.668670654296875]\n",
      " [-0.07555389404296875]\n",
      " [-23.8758544921875]\n",
      " [-64.16958618164062]\n",
      " [57.48707580566406]\n",
      " [35.91546630859375]\n",
      " [-62.8096923828125]\n",
      " [-406.371337890625]\n",
      " [199.5458984375]\n",
      " [97.96533203125]\n",
      " [55.2490234375]\n",
      " [5.29852294921875]\n",
      " [16.9666748046875]\n",
      " [-60.831787109375]\n",
      " [-57.234130859375]\n",
      " [-13.583740234375]\n",
      " [114.0750732421875]\n",
      " [8.658966064453125]\n",
      " [10.26223373413086]\n",
      " [-158.5234375]\n",
      " [15.008377075195312]\n",
      " [8.373186111450195]\n",
      " [-18.904888153076172]\n",
      " [3.1059727668762207]\n",
      " [54.288665771484375]\n",
      " [-195.90283203125]\n",
      " [-232.1884765625]\n",
      " [-143.021484375]\n",
      " [-120.46044921875]\n",
      " [4.694679260253906]\n",
      " [43.453857421875]\n",
      " [61.079833984375]\n",
      " [39.517242431640625]\n",
      " [12.547607421875]\n",
      " [-12.0478515625]\n",
      " [-43.120941162109375]\n",
      " [-72.0045166015625]\n",
      " [138.7802734375]\n",
      " [61.69677734375]\n",
      " [-41.84210205078125]\n",
      " [18.92138671875]\n",
      " [-12.049102783203125]\n",
      " [-0.09481620788574219]\n",
      " [163.875732421875]]\n",
      "Mean Squared Error: 3305.390502092599\n",
      "Residual Sum of Squares (RSS): 575137.9473641122\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot\n",
    "import numpy.linalg \n",
    "import numpy.random\n",
    "\n",
    "def parseData(filename):\n",
    "    csv_data = pd.read_csv(filename)\n",
    "    print(csv_data.describe())\n",
    "    numpy_data = csv_data.values\n",
    "    rows, columns = numpy_data.shape\n",
    "    X = numpy_data[:, :columns - 1]\n",
    "    y = numpy_data[:, columns - 1:]\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "def splitData(X, y, trainSplit, valSplit, testSplit):\n",
    "    trainStop = int(trainSplit * X.shape[0])\n",
    "    valStop = int((trainSplit + valSplit) * X.shape[0])\n",
    "    train_x = X[0:trainStop, :]\n",
    "    train_y = y[0:trainStop]\n",
    "    val_x = X[trainStop:valStop, :]\n",
    "    val_y = y[trainStop:valStop]\n",
    "    test_x = X[valStop:, :]\n",
    "    test_y = y[valStop:]\n",
    "    return train_x, train_y, val_x, val_y, test_x, test_y\n",
    "\n",
    "\n",
    "def normalize(X):\n",
    "    rangeX = np.zeros(X.shape[1])\n",
    "    minX = np.zeros(X.shape[1])\n",
    "    normX = np.zeros(X.shape)\n",
    "\n",
    "    for i in range(X.shape[1]):\n",
    "        minX[i] = min(X[:, i])\n",
    "        rangeX[i] = max(X[:, i]) - minX[i]\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            normX[i][j] = (X[i][j] - minX[j]) / rangeX[j]\n",
    "\n",
    "    return normX\n",
    "\n",
    "\n",
    "class LinearRegression:\n",
    "    def __init__(self):\n",
    "        self.coefficients = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Add a column of ones to the input data for the bias term\n",
    "        X = np.column_stack((np.ones(X.shape[0]), X))\n",
    "        \n",
    "        # Calculate coefficients using the closed-form solution\n",
    "        X_transpose = X.T\n",
    "        self.coefficients = np.linalg.inv(X_transpose.dot(X)).dot(X_transpose).dot(y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Add a column of ones to the input data for the bias term\n",
    "        X = np.column_stack((np.ones(X.shape[0]), X))\n",
    "        \n",
    "        # Predict using the learned coefficients\n",
    "        y_pred = X.dot(self.coefficients)\n",
    "        return y_pred\n",
    "\n",
    "    def mean_squared_error(self, y_true, y_pred):\n",
    "        # Calculate the mean squared error\n",
    "        mse = ((y_true - y_pred) ** 2).mean()\n",
    "        return mse\n",
    "    \n",
    "    \n",
    "    def rss(self, y_true, y_pred):\n",
    "        # Calculate the Residual Sum of Squares (RSS)\n",
    "        rss = ((y_true - y_pred) ** 2).sum()\n",
    "        return rss\n",
    "\n",
    "# Sample usage:\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    X,y=parseData(\"handwriting_alzheimers.csv\")\n",
    "    X = X[:, 1:]\n",
    "    y = np.where(y == \"P\", 1, y)\n",
    "    y = np.where(y == \"H\", -1, y)\n",
    "    X = normalize(X)\n",
    "#     X, y = shuffle(X, y)\n",
    "#     X, y = shuffle(X, y)\n",
    "#     X, y = shuffle(X, y)\n",
    "    \n",
    "    # Initialize the LinearRegression model\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Predict on new data\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    # Calculate mean squared error\n",
    "    mse = model.mean_squared_error(y, y_pred)\n",
    "    \n",
    "    # Print the coefficients and mean squared error\n",
    "    print(\"Coefficients:\", model.coefficients)\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "    \n",
    "    \n",
    "    # Calculate RSS\n",
    "    rss = model.rss(y, y_pred)\n",
    "    \n",
    "    # Print the RSS\n",
    "    print(\"Residual Sum of Squares (RSS):\", rss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d8984f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "        self.weights = np.zeros(self.n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.n_iterations):\n",
    "            self._update_weights()\n",
    "\n",
    "    def _update_weights(self):\n",
    "        for i in range(self.n_samples):\n",
    "            y_pred = self.predict(self.X[i])\n",
    "            update = self.learning_rate * (self.y[i] - y_pred)\n",
    "            self.weights += update * self.X[i]\n",
    "            self.bias += update\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias\n",
    "\n",
    "    def score(self, X, y):\n",
    "        predictions = np.where(self.predict(X) >= 0, 1, -1)\n",
    "        accuracy = np.mean(predictions == y)\n",
    "        return accuracy\n",
    "if __name__ == \"__main__\":\n",
    "    X,y=parseData(\"handwriting_alzheimers.csv\")\n",
    "    X = X[:, 1:]\n",
    "    y = np.where(y == \"P\", 1, y)\n",
    "    y = np.where(y == \"H\", -1, y)\n",
    "    X = normalize(X)\n",
    "    X, y = shuffle(X, y)\n",
    "    X, y = shuffle(X, y)\n",
    "    X, y = shuffle(X, y)\n",
    "    \n",
    "    # Convert y to float type\n",
    "    y = np.where(y == \"P\", 1, -1)\n",
    "\n",
    "    # Insert a column of ones (bias term) to X\n",
    "    X = np.insert(X, 0, 1, axis=1)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize and train the model\n",
    "    model = Perceptron(learning_rate=0.001, n_iterations=10000)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Calculate accuracy on the test set\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6557f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
